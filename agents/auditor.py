"""
agents/auditor.py â€” å®¡è®¡è€… Agent

å°è£… AnalysisService + LLMï¼Œæ˜¯ V2 çš„æ ¸å¿ƒæ™ºèƒ½ä½“ã€‚
å…·å¤‡è‡ªä¸»å†³ç­–èƒ½åŠ›: æ ¹æ®åˆæ­¥æ£€æŸ¥ç»“æœå†³å®šæ˜¯å¦è¿½åŠ  LLM æ·±åº¦åˆ†æã€‚

LLM åç«¯: æ™ºè°± GLM (å…¼å®¹ OpenAI API æ ¼å¼)
"""

from __future__ import annotations

from typing import Any

from loguru import logger

from agents.base import BaseAgent
from core.config import get_settings
from services.analyzer import AnalysisService
from services.etherscan import EtherscanService
from domain.models import AuditReport, RiskFlag, SimulationResult, Token


class AuditorAgent(BaseAgent):
    """å®¡è®¡è€… Agent â€” ç»¼åˆè§„åˆ™å¼•æ“ + LLM åšé£é™©åˆ¤æ–­ã€‚

    åŒæ¨¡å¼:
      standard     â€” è§„åˆ™å¼•æ“è¯„åˆ† (å¿«é€Ÿ)
      deep_analysis â€” æ‹‰å–æºç  + LLM åˆ†æ (ç²¾å‡†ä½†æ…¢)

    è‡ªä¸»å†³ç­–:
      - å‘ç° HIDDEN_MINT ä½†è¯„åˆ†ä¸é«˜ â†’ è¿½åŠ æ·±åº¦åˆ†æ
      - ä»¿çœŸæ­£å¸¸ä½† ownership æœªæ”¾å¼ƒ â†’ è¿½åŠ æ·±åº¦åˆ†æ
    """

    name = "AuditorAgent"

    def __init__(self) -> None:
        self._analyzer = AnalysisService()
        self._etherscan = EtherscanService()
        self._settings = get_settings()
        self._llm_client = None

    def _get_llm_client(self):
        """æ‡’åŠ è½½ LLM å®¢æˆ·ç«¯ã€‚"""
        if self._llm_client is None and self._settings.llm_api_key:
            from openai import AsyncOpenAI
            self._llm_client = AsyncOpenAI(
                api_key=self._settings.llm_api_key,
                base_url=self._settings.llm_base_url,
            )
        return self._llm_client

    async def run(self, task: dict[str, Any]) -> dict[str, Any]:
        """æ‰§è¡Œå®¡è®¡ã€‚

        task keys:
          token: Token å¯¹è±¡
          simulation: SimulationResult å¯¹è±¡
          mode: "standard" | "deep_analysis"  (é»˜è®¤ standard)

        è¿”å›:
          report: AuditReport
          llm_analysis: str | None  (æ·±åº¦åˆ†æç»“æœ)
          decision: str  (Agent çš„å†³ç­–)
        """
        token: Token = task["token"]
        simulation: SimulationResult = task["simulation"]
        mode = task.get("mode", "standard")

        # æ ‡å‡†å®¡è®¡: è§„åˆ™å¼•æ“
        report = await self._analyzer.analyze(token, simulation)

        result = {
            "report": report,
            "llm_analysis": None,
            "decision": "standard_complete",
        }

        # è‡ªä¸»å†³ç­–: æ˜¯å¦éœ€è¦æ·±åº¦åˆ†æ
        decision = await self.decide({
            "flags": [f.value for f in report.risk_flags],
            "score": report.risk_score,
            "can_sell": simulation.can_sell,
            "mode": mode,
        })

        result["decision"] = decision

        if decision == "need_deep_analysis" or mode == "deep_analysis":
            self.log("è§¦å‘æ·±åº¦åˆ†æ â€” æ­£åœ¨è·å–åˆçº¦æºç å¹¶è°ƒç”¨ LLM")
            llm_analysis = await self._deep_analyze(token, simulation, report)
            result["llm_analysis"] = llm_analysis

            # å°† LLM åˆ†æè¿½åŠ åˆ°æŠ¥å‘Šçš„ llm_summary
            if llm_analysis:
                enhanced_summary = (
                    f"{report.llm_summary}\n\n"
                    f"ğŸ¤– **AI æ·±åº¦åˆ†æ (GLM)**:\n{llm_analysis}"
                )
                # åˆ›å»ºå¢å¼ºç‰ˆæŠ¥å‘Š
                result["report"] = AuditReport(
                    token=report.token,
                    simulation=report.simulation,
                    risk_score=report.risk_score,
                    risk_flags=report.risk_flags,
                    llm_summary=enhanced_summary,
                )

        return result

    async def decide(self, context: dict[str, Any]) -> str:
        """è‡ªä¸»å†³ç­–: æ˜¯å¦éœ€è¦è¿½åŠ  LLM æ·±åº¦åˆ†æã€‚"""
        flags = context.get("flags", [])
        score = context.get("score", 0)
        can_sell = context.get("can_sell", True)
        mode = context.get("mode", "standard")

        # å¦‚æœæ˜ç¡®è¦æ±‚æ·±åº¦åˆ†æ
        if mode == "deep_analysis":
            return "need_deep_analysis"

        # æ²¡æœ‰ LLM API Key â†’ æ— æ³•åšæ·±åº¦åˆ†æ
        if not self._settings.llm_api_key:
            return "done"

        # å†³ç­–è§„åˆ™:
        # 1. å‘ç° HIDDEN_MINT ä½†è¯„åˆ†ä¸é«˜ â†’ éœ€è¦ç¡®è®¤
        if "HIDDEN_MINT" in flags and score < 50:
            return "need_deep_analysis"

        # 2. ä»¿çœŸæ­£å¸¸ä½† ownership æœªæ”¾å¼ƒ â†’ è¿½åŠ åˆ†æ
        if can_sell and "OWNERSHIP_NOT_RENOUNCED" in flags:
            return "need_deep_analysis"

        # 3. é«˜é£é™©ä½†åŸå› ä¸æ˜ â†’ è¿½åŠ åˆ†æ
        if score >= 60 and "UNKNOWN_RISK" in flags:
            return "need_deep_analysis"

        return "done"

    async def _deep_analyze(
        self,
        token: Token,
        simulation: SimulationResult,
        report: AuditReport,
    ) -> str | None:
        """è°ƒç”¨ LLM (GLM) å¯¹åˆçº¦æºç è¿›è¡Œæ·±åº¦åˆ†æã€‚"""
        client = self._get_llm_client()
        if not client:
            self.log("æœªé…ç½® LLM API Keyï¼Œè·³è¿‡æ·±åº¦åˆ†æ")
            return None

        # 1. å°è¯•è·å–åˆçº¦æºç 
        source_code = None
        try:
            source_code = await self._etherscan.get_contract_source(
                token.address
            )
        except Exception as e:
            self.log_error(f"è·å–æºç å¤±è´¥: {e}")

        # 2. æ„å»º Prompt
        flags_str = ", ".join(f.value for f in report.risk_flags)

        if source_code:
            truncated = source_code[:8000]
            prompt = (
                "ä½ æ˜¯ä¸€åèµ„æ·±æ™ºèƒ½åˆçº¦å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚\n"
                "è¯·åˆ†æä»¥ä¸‹ ERC-20 ä»£å¸åˆçº¦æºç ï¼Œé‡ç‚¹å…³æ³¨:\n"
                "1. æ˜¯å¦æœ‰éšè—çš„ mint/å¢å‘å‡½æ•°\n"
                "2. owner æ˜¯å¦æœ‰å¼‚å¸¸æƒé™ (ä¿®æ”¹ç¨ç‡ã€æš‚åœè½¬è´¦ã€é»‘åå•)\n"
                "3. transfer å‡½æ•°æ˜¯å¦æœ‰éšè—é€»è¾‘\n"
                "4. æ˜¯å¦æœ‰å¯ç–‘çš„ proxy/delegatecall\n\n"
                f"ä»£å¸åœ°å€: {token.address}\n"
                f"ä»¿çœŸç»“æœ: å¯ä¹°={simulation.can_buy}, å¯å–={simulation.can_sell}\n"
                f"ä¹°å…¥ç¨: {simulation.buy_tax_pct:.1f}%, "
                f"å–å‡ºç¨: {simulation.sell_tax_pct:.1f}%\n"
                f"å·²è§¦å‘æ ‡ç­¾: [{flags_str}]\n"
                f"é£é™©è¯„åˆ†: {report.risk_score:.1f}/100\n\n"
                f"åˆçº¦æºç  (èŠ‚é€‰):\n```solidity\n{truncated}\n```\n\n"
                "è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œ300 å­—ä»¥å†…ã€‚"
            )
        else:
            prompt = (
                "ä½ æ˜¯ä¸€åèµ„æ·±æ™ºèƒ½åˆçº¦å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚\n"
                "ä»¥ä¸‹ä»£å¸åˆçº¦æœªå¼€æºï¼Œæ— æ³•è·å–æºç ã€‚è¯·æ ¹æ®é“¾ä¸Šæ£€æŸ¥ç»“æœç»™å‡ºé£é™©è¯„ä¼°:\n\n"
                f"ä»£å¸åœ°å€: {token.address}\n"
                f"ä»£å¸ç¬¦å·: {token.symbol or 'æœªçŸ¥'}\n"
                f"ä»¿çœŸç»“æœ: å¯ä¹°={simulation.can_buy}, å¯å–={simulation.can_sell}\n"
                f"ä¹°å…¥ç¨: {simulation.buy_tax_pct:.1f}%, "
                f"å–å‡ºç¨: {simulation.sell_tax_pct:.1f}%\n"
                f"å·²è§¦å‘æ ‡ç­¾: [{flags_str}]\n"
                f"é£é™©è¯„åˆ†: {report.risk_score:.1f}/100\n\n"
                "è¯·ç”¨ä¸­æ–‡åˆ†æè¿™äº›æŒ‡æ ‡æ„å‘³ç€ä»€ä¹ˆé£é™©ï¼Œ200 å­—ä»¥å†…ã€‚"
            )

        # 3. è°ƒç”¨ GLM API
        try:
            response = await client.chat.completions.create(
                model=self._settings.llm_model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ MemeScan AI å®‰å…¨å®¡è®¡åŠ©æ‰‹ï¼Œä¸“é—¨åˆ†æ Memecoin åˆçº¦å®‰å…¨æ€§ã€‚",
                    },
                    {"role": "user", "content": prompt},
                ],
                max_tokens=500,
                temperature=0.3,
            )
            result = response.choices[0].message.content.strip()
            self.log(f"LLM åˆ†æå®Œæˆ ({len(result)} å­—)")
            return result
        except Exception as e:
            self.log_error(f"LLM è°ƒç”¨å¤±è´¥: {e}")
            return f"AI åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {e}"
